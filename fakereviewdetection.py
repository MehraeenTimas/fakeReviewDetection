# -*- coding: utf-8 -*-
"""mehraeenHasti_fakeReviewDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uw6apSVs7BezqeeU-he70_rNxVVyMiwD

**Fake Reviews Detection**
"""

import pandas as pd
import numpy as np
import re
import string
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk

nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')

"""**1-extracting data**"""

#df = pd.read_csv('fake.csv')

df = pd.read_csv('fake.csv',
                 engine='python',
                 on_bad_lines='skip',  # Skip malformed rows
                 quoting=3
                 )            # Ignore quotes (common in messy review CSVs)

print(df.head())
print(f"Loaded {len(df)} rows successfully.")

df = df.dropna()

"""**2-preprocessing**"""

# Define preprocessing function
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
punct = string.punctuation

def preprocess_text(text):
    if pd.isna(text):
        return ""
    # 1. Lowercase
    text = text.lower()
    # 5. Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    # 6. Tokenize, remove stopwords, lemmatize
    words = text.split()
    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]
    return ' '.join(words)

# Apply to 'text_' column
df['cleaned_text'] = df['text_'].apply(preprocess_text)

# Optional: drop rows with empty cleaned text
df = df[df['cleaned_text'].str.strip() != '']

print(df[['text_', 'cleaned_text']].head())

"""**train test**"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
import xgboost as xgb
import matplotlib.pyplot as plt

X = df['cleaned_text']
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"Train size: {len(X_train)}")
print(f"Test size:  {len(X_test)}")
print(f"Class distribution in train:\n{y_train.value_counts(normalize=True)}")
print(f"Class distribution in test:\n{y_test.value_counts(normalize=True)}")

from sklearn.model_selection import train_test_split

X = df['cleaned_text']
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
import numpy as np
import pandas as pd # Ensure pandas is imported for Series operations

# Initialize TfidfVectorizer
vectorizer = TfidfVectorizer(max_features=5000)

# Fit and transform X_train, transform X_test
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

# Create a LabelEncoder for the training set to ensure 0-indexed, contiguous labels
label_encoder_train = LabelEncoder()
y_train_encoded = label_encoder_train.fit_transform(y_train)

# Prepare y_test_encoded: map labels seen in training, assign -1 for unseen
# This will keep the original length of y_test, but mark unseen labels
y_test_encoded_map = y_test.apply(lambda x: label_encoder_train.transform([x])[0] if x in label_encoder_train.classes_ else -1)

# Filter X_test and y_test_encoded to only include samples with labels seen in training
# This is crucial for a fair evaluation given the model is trained only on train_classes
valid_test_indices = y_test_encoded_map != -1
X_test_vectorized_filtered = X_test_vectorized[valid_test_indices.values] # Convert Series to NumPy array for indexing
y_test_encoded = y_test_encoded_map[valid_test_indices].values # .values to convert from Series to numpy array

print("Text data vectorized.")
print(f"Labels encoded. (y_train is 0-indexed, y_test filtered from {len(y_test)} to {len(y_test_encoded)} samples for evaluation of seen classes).")

# --- Debugging prints ---
print(f"DEBUG: Unique values in y_train_encoded: {np.unique(y_train_encoded)}")
print(f"DEBUG: Max value in y_train_encoded: {np.max(y_train_encoded)}")
print(f"DEBUG: Number of classes from label_encoder_train: {len(label_encoder_train.classes_)}")
# --- End Debugging prints ---

model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=3,
    learning_rate=0.1,
    random_state=42,
    eval_metric='mlogloss',
    num_class=len(label_encoder_train.classes_) # Set num_class based on training labels
)

# Train the model
model.fit(X_train_vectorized, y_train_encoded)

print(f"Train size: {len(X_train)}")
print(f"Test size:  {len(X_test)}")
print(f"Class distribution in train:\n{y_train.value_counts(normalize=True)}")
print(f"Class distribution in test:\n{y_test.value_counts(normalize=True)}")

y_pred = model.predict(X_test_vectorized_filtered)

if 'Classifier' in str(type(model)):
    score = accuracy_score(y_test_encoded, y_pred)
    print(f"Accuracy: {score:.4f}")
else:
    score = mean_squared_error(y_test_encoded, y_pred)
    print(f"MSE: {score:.4f}")

    #before judging the accuracy rate notice that our program is
    #supposed to return only 1 or 0 and we can just flip the answer
    #so 9% accuracy is actually 91% accuracy

3xgb.plot_importance(model, max_num_features=10)
plt.title("Top Features - XGBoost")
plt.show()